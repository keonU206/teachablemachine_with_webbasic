<!DOCTYPE html>
<html>
<head>
  <title>Teachable Machine 응용 웹 사이트 구축</title>
  <link href="style.css" type="text/css" rel="stylesheet">
</head>
<body>
  <header>
    <h1>Teachable Machine 응용 웹 사이트 구축</h1>
  </header>


  <nav>
    <ul>
      <li><a href="#">상단</a></li>
      <li><a href="#">메뉴</a></li>
      <li><a href="#">바</a></li>
      <li><a href="#">링크</a></li>
      <li><a href="#">연결되어</a></li>
      <li><a href="#">있지 않아요</a></li>
    </ul>
  </nav>

  <section>
    <div id="date"></div>
    <div id="clock"></div>
  </section>

  <section>
    <h2>Teachable Machine이란?</h2>
    <p>
        Teachable Machine은 Google에서 제공하는 머신 러닝 모델을 만들고 훈련시킬 수 있는 웹 기반 도구입니다. 이 도구를 사용하면 개발자나 비전문가도 AI 모델을 만들고, 이미지, 음성, 자세 등 다양한 입력 데이터를 분류하거나 인식하는 데 사용할 수 있습니다.
        Teachable Machine은 사용자 친화적인 인터페이스를 제공하여 누구나 쉽게 모델을 만들 수 있도록 도와줍니다. 사용자는 웹캠이나 이미지, 오디오, 자세 데이터를 입력으로 사용하여 모델을 훈련시킬 수 있습니다. 모델을 훈련시키는 동안 실시간으로 입력 데이터를 분석하고, 사용자는 분류 레이블을 할당하여 해당 데이터를 학습시킵니다.
        훈련된 모델은 웹 기반으로 내보낼 수 있으며, 이를 웹 사이트, 앱, 인터랙티브 예술 작품 등에서 활용할 수 있습니다. Teachable Machine은 웹 기술을 활용하여 머신 러닝 모델을 만들고 배포하는 과정을 간소화하였기 때문에, 기술적인 전문 지식이 없어도 누구나 쉽게 활용할 수 있는 장점이 있습니다.
    </p>
  </section>
  <hr>
  
  <section>
    <h2>Teachable Machine 소개</h2>
    <ul>
      <li>사이트</li>
      <li>이미지 프로젝트 이용 방법</li>
      <li>오디오 프로젝트 이용 방법</li>
      <li>포즈 프로젝트 이용방법</li>
      <li>생활코딩과 함께하는 Teachable Machine 응용 웹 사이트 구축</li>
    </ul>
  </section>
  <hr>

  <section>
    <a href="https://teachablemachine.withgoogle.com/train" target="_blank">
        Teachable Machine사이트로 이동
    </a>
    <hr>
    <p class="s_title">이미지 프로젝트 이용방법</p>
    <p>
        Teachable Machine을 사용하여 이미지 프로젝트를 진행하는 방법은 다음과 같습니다:<br><br>

        1)Teachable Machine 웹사이트에 접속합니다.<br><br>

        2)"Get Started" 버튼을 클릭하여 프로젝트를 생성합니다.<br><br>

        3)프로젝트 생성 후, "Image Project" 옵션을 선택합니다.<br><br>

        4)이미지 프로젝트를 위한 클래스(class)를 추가합니다. 예를 들어, 고양이, 개, 새로운 클래스를 추가하고자 한다면, "Add a class" 버튼을 클릭하고 클래스의 이름과 색상을 지정합니다.<br><br>

        5)각 클래스에 대해 데이터를 수집합니다. 웹캠을 사용하여 실시간으로 이미지를 캡처하거나, 로컬 파일로 이미지를 업로드할 수 있습니다. 각 클래스마다 다양한 각도, 조명, 배경 등 다양한 조건에서 이미지를 촬영하고 클래스에 할당합니다.<br><br>

        6)데이터 수집이 완료되면, "Train Model" 버튼을 클릭하여 머신 러닝 모델을 훈련시킵니다. Teachable Machine은 수집한 데이터를 기반으로 분류 모델을 자동으로 생성합니다.<br><br>

        7)모델 훈련이 완료되면, "Test" 섹션에서 모델을 테스트할 수 있습니다. 웹캠을 통해 실시간 이미지를 입력하거나, 로컬 파일로 이미지를 업로드하여 모델이 어떻게 분류하는지 확인할 수 있습니다.<br><br>

        8)마지막으로, "Export Model"을 선택하여 모델을 내보낼 수 있습니다. Teachable Machine은 TensorFlow.js, TensorFlow Lite 등 다양한 형식으로 모델을 내보내고, 이를 웹사이트나 앱에서 활용할 수 있습니다.<br><br>

        위의 단계를 따라가면 Teachable Machine을 사용하여 이미지 프로젝트를 만들고 훈련시킬 수 있습니다. 프로젝트에 따라 데이터 수집과 모델 훈련을 반복하며 성능을 개선할 수도 있습니다. Teachable Machine의 사용자 친화적인 인터페이스를 통해 비전문가도 쉽게 머신 러닝 모델을 구축하고 다양한 응용 분야에서 활용할 수 있습니다.
    </p>
    <hr>
    <p class="s_title">오디오 프로젝트 이용방법</p>
    <p>
        Teachable Machine을 사용하여 오디오 프로젝트를 진행하는 방법은 다음과 같습니다:<br><br>

        1)Teachable Machine 웹사이트에 접속합니다.<br><br>

        2)"Get Started" 버튼을 클릭하여 프로젝트를 생성합니다.<br><br>

        3)프로젝트 생성 후, "Audio Project" 옵션을 선택합니다.<br><br>

        4)오디오 프로젝트를 위한 클래스(class)를 추가합니다. 예를 들어, 소리 A, 소리 B, 소리 C 등의 클래스를 추가하고자 한다면, "Add a class" 버튼을 클릭하고 클래스의 이름과 색상을 지정합니다.<br><br>

        5)각 클래스에 대해 데이터를 수집합니다. Teachable Machine에서는 10초 이내의 오디오 클립을 녹음하여 데이터로 사용할 수 있습니다. 클래스마다 다양한 소리를 녹음하고, 클래스에 할당합니다.<br><br>

        6)데이터 수집이 완료되면, "Train Model" 버튼을 클릭하여 머신 러닝 모델을 훈련시킵니다. Teachable Machine은 수집한 데이터를 기반으로 분류 모델을 자동으로 생성합니다.<br><br>

        7)모델 훈련이 완료되면, "Test" 섹션에서 모델을 테스트할 수 있습니다. 오디오를 녹음하여 모델이 어떻게 분류하는지 확인할 수 있습니다.<br><br>

        8)마지막으로, "Export Model"을 선택하여 모델을 내보낼 수 있습니다. Teachable Machine은 TensorFlow.js, TensorFlow Lite 등 다양한 형식으로 모델을 내보내고, 이를 웹사이트나 앱에서 활용할 수 있습니다.<br><br>

        위의 단계를 따라가면 Teachable Machine을 사용하여 오디오 프로젝트를 만들고 훈련시킬 수 있습니다. 데이터 수집과 모델 훈련을 반복하여 성능을 개선할 수도 있습니다. Teachable Machine의 사용자 친화적인 인터페이스를 통해 비전문가도 쉽게 머신 러닝 모델을 구축하고 다양한 응용 분야에서 오디오 데이터를 분류하는 데 활용할 수 있습니다.
    </p>
    <hr>
    <p class="s_title">포즈 프로젝트 이용방법</p>
    <p>
        Teachable Machine을 사용하여 포즈(자세) 프로젝트를 진행하는 방법은 다음과 같습니다<br><br>

        1)Teachable Machine 웹사이트에 접속합니다.<br><br>

        2)"Get Started" 버튼을 클릭하여 프로젝트를 생성합니다.<br><br>

        3)프로젝트 생성 후, "Pose Project" 옵션을 선택합니다.<br><br>

        4)포즈 프로젝트를 위한 클래스(class)를 추가합니다. 예를 들어, "상단 위로 손을 뻗은 자세", "하체를 구부리는 자세" 등의 클래스를 추가하고자 한다면, "Add a class" 버튼을 클릭하고 클래스의 이름과 색상을 지정합니다.<br><br>

        5)각 클래스에 대해 데이터를 수집합니다. Teachable Machine에서는 웹캠을 사용하여 실시간으로 포즈를 촬영하고, 클래스에 할당할 수 있습니다. 각 클래스마다 다양한 포즈를 촬영하고, 클래스에 할당합니다.<br><br>

        6)데이터 수집이 완료되면, "Train Model" 버튼을 클릭하여 머신 러닝 모델을 훈련시킵니다. Teachable Machine은 수집한 데이터를 기반으로 분류 모델을 자동으로 생성합니다.<br><br>

        7)모델 훈련이 완료되면, "Test" 섹션에서 모델을 테스트할 수 있습니다. 웹캠을 통해 실시간으로 포즈를 입력하고, 모델이 어떻게 분류하는지 확인할 수 있습니다.<br><br>

        8)마지막으로, "Export Model"을 선택하여 모델을 내보낼 수 있습니다. Teachable Machine은 TensorFlow.js, TensorFlow Lite 등 다양한 형식으로 모델을 내보내고, 이를 웹사이트나 앱에서 활용할 수 있습니다.<br><br>

        위의 단계를 따라가면 Teachable Machine을 사용하여 포즈 프로젝트를 만들고 훈련시킬 수 있습니다. 데이터 수집과 모델 훈련을 반복하여 성능을 개선할 수도 있습니다. Teachable Machine의 사용자 친화적인 인터페이스를 통해 비전문가도 쉽게 머신 러닝 모델을 구축하고 다양한 응용 분야에서 포즈 데이터를 분류하고 식별하는 데 활용할 수 있습니다.
    </p>
    <hr>
    <p class="s_title">생활코딩과 함께하는 Teachable Machine 응용 웹 사이트 구축</p>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/ZFa1DrjTzmQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
  </section>

  <footer>
    <p>&copy; 2023 Teachable Machine 응용 웹 사이트 구축</p>
  </footer>
    <script src="clock.js" type="text/javascript"></script>
<div style="visibility: hidden; position: absolute;" id="webcam-container"></div>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@latest/dist/teachablemachine-image.min.js"></script>
<script type="text/javascript">
    // More API functions here:
    // https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/image

    // the link to your model provided by Teachable Machine export panel
    const URL = "https://teachablemachine.withgoogle.com/models/RWnEto46M/";

    let model, webcam, maxPredictions;

    // Load the image model and setup the webcam
    async function init() {
        const modelURL = URL + "model.json";
        const metadataURL = URL + "metadata.json";

        // load the model and metadata
        // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
        // or files from your local hard drive
        // Note: the pose library adds "tmImage" object to your window (window.tmImage)
        model = await tmImage.load(modelURL, metadataURL);
        maxPredictions = model.getTotalClasses();

        // Convenience function to setup a webcam
        const flip = true; // whether to flip the webcam
        webcam = new tmImage.Webcam(200, 200, flip); // width, height, flip
        await webcam.setup(); // request access to the webcam
        await webcam.play();
        window.requestAnimationFrame(loop);

        // append elements to the DOM
        document.getElementById("webcam-container").appendChild(webcam.canvas);
    }

    async function loop() {
        webcam.update(); // update the webcam frame
        await predict();
        window.requestAnimationFrame(loop);
    }

    // run the webcam image through the image model
    async function predict() {
        // predict can take in an image, video or canvas html element
        const prediction = await model.predict(webcam.canvas);
        if(prediction[0].probability > 0.5){
            console.log("Day");
            document.querySelector("body").style.backgroundColor = "white";
            document.querySelector("body").style.color = "black";
        }else{
            console.log("Night");
            document.querySelector("body").style.backgroundColor = "black";
            document.querySelector("body").style.color = "white";
         }
    }
    init();
</script>

</body>
</html>
